{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
      "\u001b[K     |████████████████████████████████| 225 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flaml in ./.conda/envs/default/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.conda/envs/default/lib/python3.9/site-packages (from openai) (1.10.5)\n",
      "Requirement already satisfied: sniffio in ./.conda/envs/default/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Collecting typing-extensions<5,>=4.7\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.conda/envs/default/lib/python3.9/site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: tqdm>4 in ./.conda/envs/default/lib/python3.9/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/envs/default/lib/python3.9/site-packages (from openai) (0.24.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in ./.conda/envs/default/lib/python3.9/site-packages (from flaml) (1.2.2)\n",
      "Requirement already satisfied: xgboost>=0.90 in ./.conda/envs/default/lib/python3.9/site-packages (from flaml) (1.7.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.conda/envs/default/lib/python3.9/site-packages (from flaml) (1.10.0)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in ./.conda/envs/default/lib/python3.9/site-packages (from flaml) (1.23.5)\n",
      "Requirement already satisfied: lightgbm>=2.3.1 in ./.conda/envs/default/lib/python3.9/site-packages (from flaml) (3.3.5)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./.conda/envs/default/lib/python3.9/site-packages (from flaml) (1.5.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./.conda/envs/default/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in ./.conda/envs/default/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in ./.conda/envs/default/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.17.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/envs/default/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/default/lib/python3.9/site-packages (from lightgbm>=2.3.1->flaml) (0.40.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.1.4->flaml) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.conda/envs/default/lib/python3.9/site-packages (from scikit-learn>=0.24->flaml) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.conda/envs/default/lib/python3.9/site-packages (from scikit-learn>=0.24->flaml) (3.1.0)\n",
      "Installing collected packages: typing-extensions, distro, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.5.0\n",
      "    Uninstalling typing-extensions-4.5.0:\n",
      "      Successfully uninstalled typing-extensions-4.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autoviml 0.1.713 requires numpy~=1.19.5, but you have numpy 1.23.5 which is incompatible.\n",
      "autoviml 0.1.713 requires xgboost~=1.1.1, but you have xgboost 1.7.5 which is incompatible.\u001b[0m\n",
      "Successfully installed distro-1.9.0 openai-1.6.1 typing-extensions-4.9.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import datetime\n",
    "import flaml\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df = df.drop('trans_num', axis=1)\n",
    "df = df.drop('cc_num', axis=1)\n",
    "df = df.drop('unix_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {1: 'Yes', 0: 'No'}\n",
    "df['is_fraud'] = df['is_fraud'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'M': 'Male', 'F': 'Female'}\n",
    "df['gender'] = df['gender'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "df['dob'] = pd.to_datetime(df['dob'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.datetime.now().date()\n",
    "df['age'] = current_date.year - df['dob'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_yes = df[df['is_fraud'] == 'Yes'].sample(n=500, random_state=42)\n",
    "fraud_no = df[df['is_fraud'] == 'No'].sample(n=500, random_state=42)\n",
    "merged_df = pd.concat([fraud_yes, fraud_no])\n",
    "merged_df = merged_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OPENAI_API_KEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m      7\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load your JSONL data\u001b[39;00m\n",
      "File \u001b[1;32m<frozen os>:679\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'OPENAI_API_KEY'"
     ]
    }
   ],
   "source": [
    "api_key = os.environ['OPENAI_API_KEY'] \n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Load your JSONL data\n",
    "file_path = 'manual_template.jsonl'  # Replace with your actual file path\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "# Function to get embeddings from OpenAI\n",
    "def get_embeddings(text):\n",
    "    response = client.embeddings.create(input=[text], model=\"text-embedding-ada-002\")\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Convert 'output' to a binary classification target\n",
    "df['is_fraud'] = df['output'].apply(lambda x: 1 if 'Yes' in x else 0)\n",
    "\n",
    "# Get embeddings for the 'record' field\n",
    "df['embeddings'] = df['record'].apply(get_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_df = df[['embeddings', 'is_fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(embedded_df['embeddings'])\n",
    "y = embedded_df['is_fraud'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "automl = flaml.AutoML()\n",
    "automl_settings = {\n",
    "    \"time_budget\": 600,  # Maximum time in seconds for AutoML to run\n",
    "    \"task\": \"binary\",    # Task type: binary classification\n",
    "    \"log_file_name\": \"automl.log\",  # Optional log file for tracking results\n",
    "}\n",
    "\n",
    "# Search for the best model and hyperparameters\n",
    "automl.fit(X_train, y_train, **automl_settings)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = automl.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Optionally, you can access other results, such as the best model found:\n",
    "print(automl.best_estimator)\n",
    "print(automl.best_config)\n",
    "print(automl.best_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
